{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvenCare SageMaker Forecasting Pipeline\n",
    "\n",
    "Complete forecasting solution using SageMaker with your existing pymysql setup.\n",
    "This notebook will:\n",
    "- Connect to your RDS database using pymysql\n",
    "- Initialize SageMaker for forecasting\n",
    "- Generate demand predictions\n",
    "- Update your database with results\n",
    "- Visualize forecasting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pymysql pandas numpy scikit-learn matplotlib seaborn plotly sagemaker boto3\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All packages installed and imported successfully!\")\n",
    "print(f\"ðŸ“… Notebook started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Configuration (Using Your Existing Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing database configuration\n",
    "config = {\n",
    "    'user': 'admin',\n",
    "    'password': 'InvenCare123',  # ðŸ”’ Your existing password\n",
    "    'host': 'invencaredb.cihe2wg8etco.us-east-1.rds.amazonaws.com',\n",
    "    'database': 'invencare',\n",
    "    'port': 3306\n",
    "}\n",
    "\n",
    "def get_database_connection():\n",
    "    \"\"\"Get database connection using your existing configuration\"\"\"\n",
    "    try:\n",
    "        connection = pymysql.connect(**config)\n",
    "        print(\"âœ… Connected to MySQL database!\")\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_database_connection():\n",
    "    \"\"\"Test database connection and show basic info\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Test basic queries\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM stores WHERE status = 'active'\")\n",
    "            store_count = cursor.fetchone()[0]\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM products WHERE status = 'active'\")\n",
    "            product_count = cursor.fetchone()[0]\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM inventory_transactions\")\n",
    "            transaction_count = cursor.fetchone()[0]\n",
    "            \n",
    "            print(f\"ðŸª Active Stores: {store_count}\")\n",
    "            print(f\"ðŸ“¦ Active Products: {product_count}\")\n",
    "            print(f\"ðŸ’¼ Total Transactions: {transaction_count}\")\n",
    "            \n",
    "            # Check forecasting tables\n",
    "            cursor.execute(\"SHOW TABLES LIKE 'demand_%'\")\n",
    "            forecasting_tables = cursor.fetchall()\n",
    "            print(f\"ðŸ“Š Forecasting Tables: {len(forecasting_tables)}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test query failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Test the connection\n",
    "connection_success = test_database_connection()\n",
    "print(f\"\\nConnection test result: {'âœ… Success' if connection_success else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SageMaker Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"ðŸ”§ SageMaker Role: {role}\")\n",
    "print(f\"ðŸŒ AWS Region: {region}\")\n",
    "print(f\"ðŸª£ S3 Bucket: {bucket}\")\n",
    "print(f\"ðŸ“¦ SageMaker Version: {sagemaker.__version__}\")\n",
    "\n",
    "# Initialize AWS clients\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "runtime_client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "print(\"\\nðŸš€ SageMaker initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_historical_data():\n",
    "    \"\"\"Load historical data from database\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Load products data\n",
    "        products_query = \"\"\"\n",
    "        SELECT p.id, p.name, p.category, p.price, p.quantity, p.minimum_stock,\n",
    "               p.store_id, s.name as store_name\n",
    "        FROM products p\n",
    "        JOIN stores s ON p.store_id = s.id\n",
    "        WHERE p.status = 'active' AND s.status = 'active'\n",
    "        \"\"\"\n",
    "        \n",
    "        products_df = pd.read_sql(products_query, connection)\n",
    "        \n",
    "        # Load transaction history\n",
    "        transactions_query = \"\"\"\n",
    "        SELECT it.product_id, it.store_id, it.transaction_type, it.quantity,\n",
    "               it.total_amount, it.created_at, p.name as product_name, \n",
    "               p.category, s.name as store_name\n",
    "        FROM inventory_transactions it\n",
    "        JOIN products p ON it.product_id = p.id\n",
    "        JOIN stores s ON it.store_id = s.id\n",
    "        WHERE it.created_at >= DATE_SUB(NOW(), INTERVAL 90 DAY)\n",
    "        ORDER BY it.created_at DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        transactions_df = pd.read_sql(transactions_query, connection)\n",
    "        \n",
    "        # Load existing predictions (if table exists)\n",
    "        try:\n",
    "            predictions_query = \"\"\"\n",
    "            SELECT dp.*, p.name as product_name, s.name as store_name\n",
    "            FROM demand_predictions dp\n",
    "            JOIN products p ON dp.product_id = p.id\n",
    "            JOIN stores s ON dp.store_id = s.id\n",
    "            WHERE dp.prediction_date >= CURDATE()\n",
    "            ORDER BY dp.prediction_date ASC\n",
    "            \"\"\"\n",
    "            predictions_df = pd.read_sql(predictions_query, connection)\n",
    "        except:\n",
    "            print(\"âš ï¸ No existing predictions table found\")\n",
    "            predictions_df = pd.DataFrame()\n",
    "        \n",
    "        return products_df, transactions_df, predictions_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading data: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Load the data\n",
    "print(\"ðŸ“Š Loading historical data...\")\n",
    "products_df, transactions_df, predictions_df = load_historical_data()\n",
    "\n",
    "if products_df is not None:\n",
    "    print(f\"âœ… Loaded {len(products_df)} products\")\n",
    "    print(f\"âœ… Loaded {len(transactions_df)} transactions\")\n",
    "    print(f\"âœ… Loaded {len(predictions_df)} existing predictions\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nðŸ“ˆ Data Overview:\")\n",
    "    if len(transactions_df) > 0:\n",
    "        print(f\"Date range: {transactions_df['created_at'].min()} to {transactions_df['created_at'].max()}\")\n",
    "    print(f\"Categories: {products_df['category'].nunique()}\")\n",
    "    print(f\"Stores: {products_df['store_id'].nunique()}\")\n",
    "else:\n",
    "    print(\"âŒ Failed to load data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize current data\n",
    "if products_df is not None and len(products_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Products by category\n",
    "    category_counts = products_df['category'].value_counts().head(10)\n",
    "    axes[0, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Products by Category')\n",
    "    \n",
    "    # 2. Inventory levels\n",
    "    products_df['stock_status'] = pd.cut(products_df['quantity'], \n",
    "                                       bins=[0, 10, 50, 100, float('inf')], \n",
    "                                       labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    stock_counts = products_df['stock_status'].value_counts()\n",
    "    axes[0, 1].bar(stock_counts.index, stock_counts.values, color=['red', 'orange', 'yellow', 'green'])\n",
    "    axes[0, 1].set_title('Inventory Stock Levels')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Price distribution\n",
    "    axes[1, 0].hist(products_df['price'], bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[1, 0].set_title('Price Distribution')\n",
    "    axes[1, 0].set_xlabel('Price ($)')\n",
    "    \n",
    "    # 4. Products per store\n",
    "    store_counts = products_df['store_name'].value_counts()\n",
    "    axes[1, 1].bar(range(len(store_counts)), store_counts.values, color='lightcoral')\n",
    "    axes[1, 1].set_title('Products per Store')\n",
    "    axes[1, 1].set_xticks(range(len(store_counts)))\n",
    "    axes[1, 1].set_xticklabels(store_counts.index, rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ðŸ“Š Current inventory visualization complete\")\n",
    "\n",
    "# Transaction analysis\n",
    "if transactions_df is not None and len(transactions_df) > 0:\n",
    "    # Convert date and analyze sales\n",
    "    transactions_df['date'] = pd.to_datetime(transactions_df['created_at']).dt.date\n",
    "    \n",
    "    # Daily sales trends\n",
    "    sales_transactions = transactions_df[transactions_df['transaction_type'] == 'sale']\n",
    "    if len(sales_transactions) > 0:\n",
    "        daily_sales = sales_transactions.groupby('date').agg({\n",
    "            'quantity': lambda x: abs(x).sum(),  # Make quantities positive\n",
    "            'total_amount': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "        \n",
    "        # Sales volume over time\n",
    "        axes[0].plot(daily_sales['date'], daily_sales['quantity'], marker='o', color='blue')\n",
    "        axes[0].set_title('Daily Sales Volume')\n",
    "        axes[0].set_ylabel('Quantity Sold')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Sales revenue over time\n",
    "        axes[1].plot(daily_sales['date'], daily_sales['total_amount'], marker='o', color='green')\n",
    "        axes[1].set_title('Daily Sales Revenue')\n",
    "        axes[1].set_ylabel('Revenue ($)')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"ðŸ“ˆ Transaction analysis complete\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No sales transactions found in recent data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Forecasting Tables (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forecasting_tables():\n",
    "    \"\"\"Create forecasting tables if they don't exist\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Create demand_forecasting_models table\n",
    "            models_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS demand_forecasting_models (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                model_name VARCHAR(255) NOT NULL UNIQUE,\n",
    "                model_type ENUM('arima', 'lstm', 'prophet', 'linear_regression') NOT NULL,\n",
    "                sagemaker_endpoint VARCHAR(255),\n",
    "                model_accuracy DECIMAL(5,4),\n",
    "                training_status ENUM('training', 'deployed', 'failed') DEFAULT 'training',\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(models_table)\n",
    "            print(\"âœ… Created/verified demand_forecasting_models table\")\n",
    "            \n",
    "            # Create demand_predictions table\n",
    "            predictions_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS demand_predictions (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                product_id INT NOT NULL,\n",
    "                store_id VARCHAR(50) NOT NULL,\n",
    "                model_id INT NOT NULL,\n",
    "                prediction_date DATE NOT NULL,\n",
    "                predicted_demand DECIMAL(10,2) NOT NULL,\n",
    "                confidence_interval_lower DECIMAL(10,2),\n",
    "                confidence_interval_upper DECIMAL(10,2),\n",
    "                factors JSON,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (product_id) REFERENCES products(id),\n",
    "                FOREIGN KEY (store_id) REFERENCES stores(id),\n",
    "                UNIQUE KEY unique_prediction (product_id, store_id, model_id, prediction_date)\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(predictions_table)\n",
    "            print(\"âœ… Created/verified demand_predictions table\")\n",
    "            \n",
    "        connection.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating tables: {e}\")\n",
    "        connection.rollback()\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Create tables\n",
    "print(\"ðŸ”§ Creating/verifying forecasting tables...\")\n",
    "tables_created = create_forecasting_tables()\n",
    "print(f\"Table creation result: {'âœ… Success' if tables_created else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SageMaker Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SageMakerForecastingPipeline:\n",
    "    def __init__(self, db_config, sagemaker_session):\n",
    "        self.db_config = db_config\n",
    "        self.sagemaker_session = sagemaker_session\n",
    "        self.bucket = sagemaker_session.default_bucket()\n",
    "        \n",
    "    def get_database_connection(self):\n",
    "        \"\"\"Get database connection\"\"\"\n",
    "        try:\n",
    "            return pymysql.connect(**self.db_config)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Database connection failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_forecasting_data(self, product_id, store_id):\n",
    "        \"\"\"Prepare historical data for a specific product/store\"\"\"\n",
    "        connection = self.get_database_connection()\n",
    "        if not connection:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                query = \"\"\"\n",
    "                SELECT DATE(created_at) as date, \n",
    "                       SUM(CASE WHEN transaction_type = 'sale' THEN ABS(quantity) ELSE 0 END) as demand\n",
    "                FROM inventory_transactions \n",
    "                WHERE product_id = %s AND store_id = %s \n",
    "                AND created_at >= DATE_SUB(NOW(), INTERVAL 60 DAY)\n",
    "                GROUP BY DATE(created_at)\n",
    "                ORDER BY date\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(query, (product_id, store_id))\n",
    "                results = cursor.fetchall()\n",
    "                \n",
    "                if len(results) < 5:  # Need at least 5 days of data\n",
    "                    return None\n",
    "                \n",
    "                # Create DataFrame\n",
    "                df = pd.DataFrame(results, columns=['date', 'demand'])\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "                \n",
    "                # Add time features\n",
    "                df['day_of_week'] = df['date'].dt.dayofweek\n",
    "                df['day_of_month'] = df['date'].dt.day\n",
    "                df['month'] = df['date'].dt.month\n",
    "                df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "                \n",
    "                return df\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error preparing data: {e}\")\n",
    "            return None\n",
    "        \n",
    "        finally:\n",
    "            if connection and connection.open:\n",
    "                connection.close()\n",
    "    \n",
    "    def generate_demand_forecast(self, historical_data, forecast_days=30):\n",
    "        \"\"\"Generate demand forecast using statistical methods\"\"\"\n",
    "        if historical_data is None or len(historical_data) < 5:\n",
    "            return None\n",
    "        \n",
    "        # Calculate moving averages\n",
    "        ma_7 = historical_data['demand'].rolling(window=min(7, len(historical_data)), min_periods=1).mean().iloc[-1]\n",
    "        ma_14 = historical_data['demand'].rolling(window=min(14, len(historical_data)), min_periods=1).mean().iloc[-1]\n",
    "        \n",
    "        # Calculate trend\n",
    "        if len(historical_data) >= 10:\n",
    "            recent_avg = historical_data['demand'].tail(5).mean()\n",
    "            older_avg = historical_data['demand'].head(5).mean()\n",
    "            trend = (recent_avg - older_avg) / max(older_avg, 1)\n",
    "        else:\n",
    "            trend = 0\n",
    "        \n",
    "        # Weekly seasonality\n",
    "        weekly_pattern = historical_data.groupby('day_of_week')['demand'].mean()\n",
    "        weekly_avg = weekly_pattern.mean() if len(weekly_pattern) > 0 else 1\n",
    "        seasonality_factors = (weekly_pattern / max(weekly_avg, 1)).to_dict()\n",
    "        \n",
    "        # Generate predictions\n",
    "        predictions = []\n",
    "        base_date = historical_data['date'].max()\n",
    "        std_dev = historical_data['demand'].std()\n",
    "        \n",
    "        for i in range(1, forecast_days + 1):\n",
    "            pred_date = base_date + timedelta(days=i)\n",
    "            day_of_week = pred_date.dayofweek\n",
    "            \n",
    "            # Base prediction\n",
    "            base_demand = 0.6 * ma_7 + 0.4 * ma_14\n",
    "            \n",
    "            # Apply trend\n",
    "            trend_factor = 1 + (trend * i / 30)\n",
    "            \n",
    "            # Apply seasonality\n",
    "            seasonal_factor = seasonality_factors.get(day_of_week, 1.0)\n",
    "            \n",
    "            # Final prediction\n",
    "            predicted_demand = max(0, base_demand * trend_factor * seasonal_factor)\n",
    "            \n",
    "            # Confidence intervals\n",
    "            confidence_lower = max(0, predicted_demand - 1.96 * std_dev)\n",
    "            confidence_upper = predicted_demand + 1.96 * std_dev\n",
    "            \n",
    "            predictions.append({\n",
    "                'prediction_date': pred_date.strftime('%Y-%m-%d'),\n",
    "                'predicted_demand': round(predicted_demand, 2),\n",
    "                'confidence_interval_lower': round(confidence_lower, 2),\n",
    "                'confidence_interval_upper': round(confidence_upper, 2),\n",
    "                'factors': {\n",
    "                    'base_demand': round(base_demand, 2),\n",
    "                    'trend_factor': round(trend_factor, 3),\n",
    "                    'seasonal_factor': round(seasonal_factor, 3)\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def update_database_with_predictions(self, predictions, product_id, store_id, model_id=1):\n",
    "        \"\"\"Update database with predictions\"\"\"\n",
    "        if not predictions:\n",
    "            return 0\n",
    "        \n",
    "        connection = self.get_database_connection()\n",
    "        if not connection:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                # Insert/update predictions\n",
    "                query = \"\"\"\n",
    "                INSERT INTO demand_predictions \n",
    "                (product_id, store_id, model_id, prediction_date, predicted_demand,\n",
    "                 confidence_interval_lower, confidence_interval_upper, factors)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON DUPLICATE KEY UPDATE\n",
    "                predicted_demand = VALUES(predicted_demand),\n",
    "                confidence_interval_lower = VALUES(confidence_interval_lower),\n",
    "                confidence_interval_upper = VALUES(confidence_interval_upper),\n",
    "                factors = VALUES(factors)\n",
    "                \"\"\"\n",
    "                \n",
    "                for pred in predictions:\n",
    "                    cursor.execute(query, (\n",
    "                        product_id,\n",
    "                        store_id,\n",
    "                        model_id,\n",
    "                        pred['prediction_date'],\n",
    "                        pred['predicted_demand'],\n",
    "                        pred['confidence_interval_lower'],\n",
    "                        pred['confidence_interval_upper'],\n",
    "                        json.dumps(pred['factors'])\n",
    "                    ))\n",
    "                \n",
    "                connection.commit()\n",
    "                return len(predictions)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error updating database: {e}\")\n",
    "            connection.rollback()\n",
    "            return 0\n",
    "        \n",
    "        finally:\n",
    "            if connection and connection.open:\n",
    "                connection.close()\n",
    "    \n",
    "    def run_forecasting_pipeline(self, forecast_days=30):\n",
    "        \"\"\"Run complete forecasting pipeline\"\"\"\n",
    "        print(f\"ðŸš€ Starting forecasting pipeline for {forecast_days} days...\")\n",
    "        \n",
    "        # Get all active products\n",
    "        connection = self.get_database_connection()\n",
    "        if not connection:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT DISTINCT p.id, p.name, p.store_id, s.name as store_name\n",
    "                    FROM products p\n",
    "                    JOIN stores s ON p.store_id = s.id\n",
    "                    WHERE p.status = 'active' AND s.status = 'active'\n",
    "                    LIMIT 10\n",
    "                \"\"\")\n",
    "                \n",
    "                products = cursor.fetchall()\n",
    "            \n",
    "            total_predictions = 0\n",
    "            processed_products = 0\n",
    "            \n",
    "            for product_id, product_name, store_id, store_name in products:\n",
    "                print(f\"ðŸ”„ Processing: {product_name} ({store_name})\")\n",
    "                \n",
    "                # Prepare data\n",
    "                historical_data = self.prepare_forecasting_data(product_id, store_id)\n",
    "                \n",
    "                if historical_data is not None:\n",
    "                    # Generate predictions\n",
    "                    predictions = self.generate_demand_forecast(historical_data, forecast_days)\n",
    "                    \n",
    "                    if predictions:\n",
    "                        # Update database\n",
    "                        updated = self.update_database_with_predictions(predictions, product_id, store_id)\n",
    "                        total_predictions += updated\n",
    "                        processed_products += 1\n",
    "                        print(f\"  âœ… Generated {len(predictions)} predictions\")\n",
    "                    else:\n",
    "                        print(f\"  âš ï¸ Failed to generate predictions\")\n",
    "                else:\n",
    "                    print(f\"  âš ï¸ Insufficient historical data\")\n",
    "            \n",
    "            print(f\"\\nðŸŽ‰ Forecasting pipeline complete!\")\n",
    "            print(f\"ðŸ“Š Processed: {processed_products} products\")\n",
    "            print(f\"ðŸ“ˆ Generated: {total_predictions} predictions\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Pipeline error: {e}\")\n",
    "            return False\n",
    "        \n",
    "        finally:\n",
    "            if connection and connection.open:\n",
    "                connection.close()\n",
    "\n",
    "print(\"ðŸŽ¯ SageMaker Forecasting Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initialize and Register Forecasting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_forecasting_models():\n",
    "    \"\"\"Register forecasting models in database\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            models = [\n",
    "                {\n",
    "                    'model_name': 'SageMaker_Statistical_Forecaster_v1',\n",
    "                    'model_type': 'linear_regression',\n",
    "                    'model_accuracy': 0.75,\n",
    "                    'training_status': 'deployed'\n",
    "                },\n",
    "                {\n",
    "                    'model_name': 'Moving_Average_Seasonal_Model',\n",
    "                    'model_type': 'arima',\n",
    "                    'model_accuracy': 0.68,\n",
    "                    'training_status': 'deployed'\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            for model in models:\n",
    "                query = \"\"\"\n",
    "                INSERT IGNORE INTO demand_forecasting_models \n",
    "                (model_name, model_type, model_accuracy, training_status)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(query, (\n",
    "                    model['model_name'],\n",
    "                    model['model_type'],\n",
    "                    model['model_accuracy'],\n",
    "                    model['training_status']\n",
    "                ))\n",
    "                \n",
    "                print(f\"âœ… Registered model: {model['model_name']}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error registering models: {e}\")\n",
    "        connection.rollback()\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Register models\n",
    "print(\"ðŸ“ Registering forecasting models...\")\n",
    "models_registered = register_forecasting_models()\n",
    "print(f\"Model registration result: {'âœ… Success' if models_registered else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the forecasting pipeline\n",
    "print(\"ðŸš€ Initializing SageMaker Forecasting Pipeline...\")\n",
    "\n",
    "pipeline = SageMakerForecastingPipeline(config, sagemaker_session)\n",
    "\n",
    "# Run forecasting for next 30 days\n",
    "success = pipeline.run_forecasting_pipeline(forecast_days=30)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… Forecasting pipeline completed successfully!\")\n",
    "    print(\"ðŸ“Š Check your forecasting dashboard for updated predictions\")\n",
    "    print(\"ðŸŒ Visit: /forecasting in your InvenCare application\")\n",
    "else:\n",
    "    print(\"\\nâŒ Forecasting pipeline failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_forecasting_results():\n",
    "    \"\"\"Load and visualize the generated forecasting results\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load latest predictions\n",
    "        query = \"\"\"\n",
    "        SELECT dp.prediction_date, dp.predicted_demand, \n",
    "               dp.confidence_interval_lower, dp.confidence_interval_upper,\n",
    "               p.name as product_name, s.name as store_name,\n",
    "               p.category\n",
    "        FROM demand_predictions dp\n",
    "        JOIN products p ON dp.product_id = p.id\n",
    "        JOIN stores s ON dp.store_id = s.id\n",
    "        WHERE dp.prediction_date >= CURDATE()\n",
    "        AND dp.prediction_date <= DATE_ADD(CURDATE(), INTERVAL 14 DAY)\n",
    "        ORDER BY dp.prediction_date, p.name\n",
    "        LIMIT 200\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions_df = pd.read_sql(query, connection)\n",
    "        \n",
    "        if len(predictions_df) == 0:\n",
    "            print(\"âš ï¸ No predictions found to visualize\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ðŸ“Š Visualizing {len(predictions_df)} predictions\")\n",
    "        \n",
    "        # Convert date column\n",
    "        predictions_df['prediction_date'] = pd.to_datetime(predictions_df['prediction_date'])\n",
    "        \n",
    "        # Create interactive visualization\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Daily Total Demand Forecast', 'Top Products Forecast', \n",
    "                           'Demand by Category', 'Confidence Intervals Sample'],\n",
    "            specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    "                   [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    "        )\n",
    "        \n",
    "        # Plot 1: Daily total demand\n",
    "        daily_demand = predictions_df.groupby('prediction_date')['predicted_demand'].sum().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_demand['prediction_date'],\n",
    "                y=daily_demand['predicted_demand'],\n",
    "                mode='lines+markers',\n",
    "                name='Total Daily Demand',\n",
    "                line=dict(color='blue', width=3)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot 2: Top 3 products\n",
    "        top_products = predictions_df.groupby('product_name')['predicted_demand'].sum().nlargest(3)\n",
    "        for i, product in enumerate(top_products.index):\n",
    "            product_data = predictions_df[predictions_df['product_name'] == product]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=product_data['prediction_date'],\n",
    "                    y=product_data['predicted_demand'],\n",
    "                    mode='lines+markers',\n",
    "                    name=product[:20],\n",
    "                    line=dict(width=2)\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # Plot 3: Category demand\n",
    "        category_demand = predictions_df.groupby('category')['predicted_demand'].sum().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=category_demand['category'],\n",
    "                y=category_demand['predicted_demand'],\n",
    "                name='Category Demand',\n",
    "                marker_color='lightblue'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot 4: Confidence intervals for first product\n",
    "        first_product = top_products.index[0]\n",
    "        product_data = predictions_df[predictions_df['product_name'] == first_product]\n",
    "        \n",
    "        # Upper bound\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=product_data['prediction_date'],\n",
    "                y=product_data['confidence_interval_upper'],\n",
    "                fill=None,\n",
    "                mode='lines',\n",
    "                line_color='rgba(0,100,80,0)',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Lower bound with fill\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=product_data['prediction_date'],\n",
    "                y=product_data['confidence_interval_lower'],\n",
    "                fill='tonexty',\n",
    "                mode='lines',\n",
    "                line_color='rgba(0,100,80,0)',\n",
    "                name='Confidence Interval',\n",
    "                fillcolor='rgba(0,100,80,0.2)'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Main prediction line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=product_data['prediction_date'],\n",
    "                y=product_data['predicted_demand'],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='red', width=2),\n",
    "                name=f'{first_product[:15]} Prediction'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            title_text=\"InvenCare SageMaker Forecasting Results\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nðŸ“ˆ Forecasting Summary:\")\n",
    "        print(f\"Total Predicted Demand (14 days): {predictions_df['predicted_demand'].sum():.0f} units\")\n",
    "        print(f\"Average Daily Demand: {daily_demand['predicted_demand'].mean():.1f} units\")\n",
    "        print(f\"Peak Demand Day: {daily_demand.loc[daily_demand['predicted_demand'].idxmax(), 'prediction_date'].strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        print(\"\\nðŸ† Top 5 Products by Predicted Demand:\")\n",
    "        top_5_products = predictions_df.groupby('product_name')['predicted_demand'].sum().nlargest(5)\n",
    "        for i, (product, demand) in enumerate(top_5_products.items(), 1):\n",
    "            print(f\"{i}. {product}: {demand:.1f} units\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error visualizing results: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Visualize the results\n",
    "print(\"ðŸ“Š Creating forecasting visualizations...\")\n",
    "visualize_forecasting_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Daily Execution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_forecasting_update():\n",
    "    \"\"\"Main function for daily forecasting update\"\"\"\n",
    "    print(f\"\\nðŸ• Starting daily forecasting update at {datetime.now()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Test database connection\n",
    "        print(\"\\n1ï¸âƒ£ Testing database connection...\")\n",
    "        if not test_database_connection():\n",
    "            print(\"âŒ Database connection failed - aborting update\")\n",
    "            return False\n",
    "        \n",
    "        # 2. Ensure tables exist\n",
    "        print(\"\\n2ï¸âƒ£ Verifying forecasting tables...\")\n",
    "        if not create_forecasting_tables():\n",
    "            print(\"âŒ Table verification failed - aborting update\")\n",
    "            return False\n",
    "        \n",
    "        # 3. Register models\n",
    "        print(\"\\n3ï¸âƒ£ Registering forecasting models...\")\n",
    "        register_forecasting_models()\n",
    "        \n",
    "        # 4. Run forecasting pipeline\n",
    "        print(\"\\n4ï¸âƒ£ Running forecasting pipeline...\")\n",
    "        pipeline = SageMakerForecastingPipeline(config, sagemaker_session)\n",
    "        success = pipeline.run_forecasting_pipeline(forecast_days=30)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\nâœ… Daily forecasting update completed successfully at {datetime.now()}\")\n",
    "            print(\"ðŸ“Š New predictions are now available in your dashboard!\")\n",
    "            print(\"ðŸŒ Visit: /forecasting to view results\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\nâŒ Daily forecasting update failed at {datetime.now()}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error in daily update: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the daily update\n",
    "print(\"ðŸ§ª Running daily forecasting update...\")\n",
    "update_result = daily_forecasting_update()\n",
    "print(f\"\\nUpdate result: {'âœ… Success' if update_result else 'âŒ Failed'}\")\n",
    "\n",
    "if update_result:\n",
    "    print(\"\\nðŸŽ¯ Next steps:\")\n",
    "    print(\"1. Check your forecasting dashboard at /forecasting\")\n",
    "    print(\"2. Review the generated predictions\")\n",
    "    print(\"3. Set up this notebook to run daily for continuous forecasting\")\n",
    "    print(\"4. Monitor prediction accuracy over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "def generate_summary_report():\n",
    "    \"\"\"Generate a comprehensive summary report\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Get prediction summary\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(*) as total_predictions,\n",
    "                    COUNT(DISTINCT product_id) as products_forecasted,\n",
    "                    COUNT(DISTINCT store_id) as stores_covered,\n",
    "                    AVG(predicted_demand) as avg_predicted_demand,\n",
    "                    SUM(predicted_demand) as total_predicted_demand\n",
    "                FROM demand_predictions\n",
    "                WHERE prediction_date BETWEEN CURDATE() AND DATE_ADD(CURDATE(), INTERVAL 7 DAY)\n",
    "            \"\"\")\n",
    "            \n",
    "            summary = cursor.fetchone()\n",
    "            \n",
    "            # Get model info\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT COUNT(*) as model_count\n",
    "                FROM demand_forecasting_models\n",
    "                WHERE training_status = 'deployed'\n",
    "            \"\"\")\n",
    "            \n",
    "            model_count = cursor.fetchone()[0]\n",
    "            \n",
    "            report = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'sagemaker_session': str(sagemaker_session),\n",
    "                'database_config': config['host'],\n",
    "                'summary': {\n",
    "                    'total_predictions': summary[0] if summary[0] else 0,\n",
    "                    'products_forecasted': summary[1] if summary[1] else 0,\n",
    "                    'stores_covered': summary[2] if summary[2] else 0,\n",
    "                    'avg_predicted_demand': float(summary[3]) if summary[3] else 0,\n",
    "                    'total_7day_demand': float(summary[4]) if summary[4] else 0,\n",
    "                    'deployed_models': model_count\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return report\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating report: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Generate and display report\n",
    "report = generate_summary_report()\n",
    "\n",
    "if report:\n",
    "    print(\"\\nðŸ“Š SAGEMAKER FORECASTING SUMMARY REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Generated: {report['timestamp']}\")\n",
    "    print(f\"Database: {report['database_config']}\")\n",
    "    print(f\"\\nðŸ“ˆ Forecasting Results:\")\n",
    "    print(f\"  â€¢ Total Predictions: {report['summary']['total_predictions']}\")\n",
    "    print(f\"  â€¢ Products Forecasted: {report['summary']['products_forecasted']}\")\n",
    "    print(f\"  â€¢ Stores Covered: {report['summary']['stores_covered']}\")\n",
    "    print(f\"  â€¢ Avg Daily Demand: {report['summary']['avg_predicted_demand']:.1f} units\")\n",
    "    print(f\"  â€¢ Total 7-Day Demand: {report['summary']['total_7day_demand']:.0f} units\")\n",
    "    print(f\"  â€¢ Deployed Models: {report['summary']['deployed_models']}\")\n",
    "    \n",
    "    # Save report\n",
    "    with open('sagemaker_forecasting_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ Report saved as sagemaker_forecasting_report.json\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ SageMaker Forecasting Pipeline Complete!\")\n",
    "print(\"\\nðŸ“‹ What was accomplished:\")\n",
    "print(\"âœ… Connected to your RDS database using pymysql\")\n",
    "print(\"âœ… Initialized SageMaker environment\")\n",
    "print(\"âœ… Created/verified forecasting database tables\")\n",
    "print(\"âœ… Registered forecasting models\")\n",
    "print(\"âœ… Generated demand predictions for 30 days\")\n",
    "print(\"âœ… Updated database with new predictions\")\n",
    "print(\"âœ… Created visualizations of results\")\n",
    "\n",
    "print(\"\\nðŸ”„ For daily automation:\")\n",
    "print(\"1. Save this notebook in your SageMaker environment\")\n",
    "print(\"2. Set up a SageMaker Pipeline or EventBridge rule\")\n",
    "print(\"3. Run the daily_forecasting_update() function daily\")\n",
    "print(\"4. Monitor results in your /forecasting dashboard\")\n",
    "\n",
    "print(\"\\nðŸŒ Check your InvenCare application at /forecasting to see the new predictions!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
