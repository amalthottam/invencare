{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvenCare SageMaker Forecasting Pipeline\n",
    "\n",
    "Complete forecasting solution using SageMaker with your existing pymysql setup.\n",
    "This notebook will:\n",
    "- Connect to your RDS database using pymysql\n",
    "- Initialize SageMaker for forecasting\n",
    "- Generate demand predictions\n",
    "- Update your database with results\n",
    "- Visualize forecasting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pymysql pandas numpy scikit-learn matplotlib seaborn plotly sagemaker boto3\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All packages installed and imported successfully!\")\n",
    "print(f\"ðŸ“… Notebook started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Configuration (Using Your Existing Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing database configuration\n",
    "config = {\n",
    "    'user': 'admin',\n",
    "    'password': 'InvenCare123',  # Your existing password\n",
    "    'host': 'invencaredb.cihe2wg8etco.us-east-1.rds.amazonaws.com',\n",
    "    'database': 'invencare',\n",
    "    'port': 3306\n",
    "}\n",
    "\n",
    "def get_database_connection():\n",
    "    \"\"\"Get database connection using your existing configuration\"\"\"\n",
    "    try:\n",
    "        connection = pymysql.connect(**config)\n",
    "        print(\"âœ… Connected to MySQL database!\")\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_database_connection():\n",
    "    \"\"\"Test database connection and show basic info\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Test basic queries\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM stores WHERE status = 'active'\")\n",
    "            store_count = cursor.fetchone()[0]\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM products WHERE status = 'active'\")\n",
    "            product_count = cursor.fetchone()[0]\n",
    "            \n",
    "            cursor.execute(\"SELECT COUNT(*) FROM inventory_transactions\")\n",
    "            transaction_count = cursor.fetchone()[0]\n",
    "            \n",
    "            print(f\"ðŸª Active Stores: {store_count}\")\n",
    "            print(f\"ðŸ“¦ Active Products: {product_count}\")\n",
    "            print(f\"ðŸ’¼ Total Transactions: {transaction_count}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test query failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Test the connection\n",
    "connection_success = test_database_connection()\n",
    "print(f\"\\nConnection test result: {'âœ… Success' if connection_success else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SageMaker Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"ðŸ”§ SageMaker Role: {role}\")\n",
    "print(f\"ðŸŒ AWS Region: {region}\")\n",
    "print(f\"ðŸª£ S3 Bucket: {bucket}\")\n",
    "print(f\"ðŸ“¦ SageMaker Version: {sagemaker.__version__}\")\n",
    "\n",
    "# Initialize AWS clients\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "runtime_client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "print(\"\\nðŸš€ SageMaker initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Forecasting Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forecasting_tables():\n",
    "    \"\"\"Create forecasting tables if they don't exist\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Create demand_forecasting_models table\n",
    "            models_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS demand_forecasting_models (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                model_name VARCHAR(255) NOT NULL UNIQUE,\n",
    "                model_type ENUM('arima', 'lstm', 'prophet', 'linear_regression') NOT NULL,\n",
    "                sagemaker_endpoint VARCHAR(255),\n",
    "                model_accuracy DECIMAL(5,4),\n",
    "                training_status ENUM('training', 'deployed', 'failed') DEFAULT 'training',\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(models_table)\n",
    "            print(\"âœ… Created/verified demand_forecasting_models table\")\n",
    "            \n",
    "            # Create demand_predictions table\n",
    "            predictions_table = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS demand_predictions (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                product_id INT NOT NULL,\n",
    "                store_id VARCHAR(50) NOT NULL,\n",
    "                model_id INT NOT NULL,\n",
    "                prediction_date DATE NOT NULL,\n",
    "                predicted_demand DECIMAL(10,2) NOT NULL,\n",
    "                confidence_interval_lower DECIMAL(10,2),\n",
    "                confidence_interval_upper DECIMAL(10,2),\n",
    "                factors JSON,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (product_id) REFERENCES products(id),\n",
    "                FOREIGN KEY (store_id) REFERENCES stores(id),\n",
    "                UNIQUE KEY unique_prediction (product_id, store_id, model_id, prediction_date)\n",
    "            )\n",
    "            \"\"\"\n",
    "            cursor.execute(predictions_table)\n",
    "            print(\"âœ… Created/verified demand_predictions table\")\n",
    "            \n",
    "        connection.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating tables: {e}\")\n",
    "        connection.rollback()\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Create tables\n",
    "print(\"ðŸ”§ Creating/verifying forecasting tables...\")\n",
    "tables_created = create_forecasting_tables()\n",
    "print(f\"Table creation result: {'âœ… Success' if tables_created else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Register Forecasting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_forecasting_models():\n",
    "    \"\"\"Register forecasting models in database\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            models = [\n",
    "                {\n",
    "                    'model_name': 'SageMaker_Statistical_Forecaster_v1',\n",
    "                    'model_type': 'linear_regression',\n",
    "                    'model_accuracy': 0.75,\n",
    "                    'training_status': 'deployed'\n",
    "                },\n",
    "                {\n",
    "                    'model_name': 'Moving_Average_Seasonal_Model',\n",
    "                    'model_type': 'arima',\n",
    "                    'model_accuracy': 0.68,\n",
    "                    'training_status': 'deployed'\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            for model in models:\n",
    "                query = \"\"\"\n",
    "                INSERT IGNORE INTO demand_forecasting_models \n",
    "                (model_name, model_type, model_accuracy, training_status)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(query, (\n",
    "                    model['model_name'],\n",
    "                    model['model_type'],\n",
    "                    model['model_accuracy'],\n",
    "                    model['training_status']\n",
    "                ))\n",
    "                \n",
    "                print(f\"âœ… Registered model: {model['model_name']}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error registering models: {e}\")\n",
    "        connection.rollback()\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Register models\n",
    "print(\"ðŸ“ Registering forecasting models...\")\n",
    "models_registered = register_forecasting_models()\n",
    "print(f\"Model registration result: {'âœ… Success' if models_registered else 'âŒ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demand_forecast(product_id, store_id, forecast_days=30):\n",
    "    \"\"\"Generate demand forecast for a specific product/store\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Get historical sales data\n",
    "            query = \"\"\"\n",
    "            SELECT DATE(created_at) as date, \n",
    "                   SUM(CASE WHEN transaction_type = 'sale' THEN ABS(quantity) ELSE 0 END) as demand\n",
    "            FROM inventory_transactions \n",
    "            WHERE product_id = %s AND store_id = %s \n",
    "            AND created_at >= DATE_SUB(NOW(), INTERVAL 60 DAY)\n",
    "            GROUP BY DATE(created_at)\n",
    "            ORDER BY date\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor.execute(query, (product_id, store_id))\n",
    "            historical_data = cursor.fetchall()\n",
    "            \n",
    "            if len(historical_data) < 5:  # Need at least 5 days of data\n",
    "                return None\n",
    "            \n",
    "            # Convert to DataFrame for easier processing\n",
    "            df = pd.DataFrame(historical_data, columns=['date', 'demand'])\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df['day_of_week'] = df['date'].dt.dayofweek\n",
    "            \n",
    "            # Calculate moving averages\n",
    "            ma_7 = df['demand'].rolling(window=min(7, len(df)), min_periods=1).mean().iloc[-1]\n",
    "            ma_14 = df['demand'].rolling(window=min(14, len(df)), min_periods=1).mean().iloc[-1]\n",
    "            \n",
    "            # Calculate trend\n",
    "            if len(df) >= 10:\n",
    "                recent_avg = df['demand'].tail(5).mean()\n",
    "                older_avg = df['demand'].head(5).mean()\n",
    "                trend = (recent_avg - older_avg) / max(older_avg, 1)\n",
    "            else:\n",
    "                trend = 0\n",
    "            \n",
    "            # Weekly seasonality\n",
    "            weekly_pattern = df.groupby('day_of_week')['demand'].mean()\n",
    "            weekly_avg = weekly_pattern.mean() if len(weekly_pattern) > 0 else 1\n",
    "            seasonality_factors = (weekly_pattern / max(weekly_avg, 1)).to_dict()\n",
    "            \n",
    "            # Generate predictions\n",
    "            predictions = []\n",
    "            base_date = df['date'].max()\n",
    "            std_dev = df['demand'].std()\n",
    "            \n",
    "            for i in range(1, forecast_days + 1):\n",
    "                pred_date = base_date + timedelta(days=i)\n",
    "                day_of_week = pred_date.dayofweek\n",
    "                \n",
    "                # Base prediction\n",
    "                base_demand = 0.6 * ma_7 + 0.4 * ma_14\n",
    "                \n",
    "                # Apply trend\n",
    "                trend_factor = 1 + (trend * i / 30)\n",
    "                \n",
    "                # Apply seasonality\n",
    "                seasonal_factor = seasonality_factors.get(day_of_week, 1.0)\n",
    "                \n",
    "                # Final prediction\n",
    "                predicted_demand = max(0, base_demand * trend_factor * seasonal_factor)\n",
    "                \n",
    "                # Confidence intervals\n",
    "                confidence_lower = max(0, predicted_demand - 1.96 * std_dev)\n",
    "                confidence_upper = predicted_demand + 1.96 * std_dev\n",
    "                \n",
    "                predictions.append({\n",
    "                    'prediction_date': pred_date.strftime('%Y-%m-%d'),\n",
    "                    'predicted_demand': round(predicted_demand, 2),\n",
    "                    'confidence_interval_lower': round(confidence_lower, 2),\n",
    "                    'confidence_interval_upper': round(confidence_upper, 2),\n",
    "                    'factors': {\n",
    "                        'base_demand': round(base_demand, 2),\n",
    "                        'trend_factor': round(trend_factor, 3),\n",
    "                        'seasonal_factor': round(seasonal_factor, 3)\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            return predictions\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating forecast: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "def insert_predictions(predictions, product_id, store_id, model_id=1):\n",
    "    \"\"\"Insert predictions into database\"\"\"\n",
    "    if not predictions:\n",
    "        return 0\n",
    "    \n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            query = \"\"\"\n",
    "            INSERT INTO demand_predictions \n",
    "            (product_id, store_id, model_id, prediction_date, predicted_demand,\n",
    "             confidence_interval_lower, confidence_interval_upper, factors)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "            predicted_demand = VALUES(predicted_demand),\n",
    "            confidence_interval_lower = VALUES(confidence_interval_lower),\n",
    "            confidence_interval_upper = VALUES(confidence_interval_upper),\n",
    "            factors = VALUES(factors)\n",
    "            \"\"\"\n",
    "            \n",
    "            for pred in predictions:\n",
    "                cursor.execute(query, (\n",
    "                    product_id,\n",
    "                    store_id,\n",
    "                    model_id,\n",
    "                    pred['prediction_date'],\n",
    "                    pred['predicted_demand'],\n",
    "                    pred['confidence_interval_lower'],\n",
    "                    pred['confidence_interval_upper'],\n",
    "                    json.dumps(pred['factors'])\n",
    "                ))\n",
    "            \n",
    "            connection.commit()\n",
    "            return len(predictions)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error inserting predictions: {e}\")\n",
    "        connection.rollback()\n",
    "        return 0\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "print(\"ðŸŽ¯ Forecasting functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Forecasting for All Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forecasting_pipeline(forecast_days=30):\n",
    "    \"\"\"Run forecasting for all active products\"\"\"\n",
    "    print(f\"ðŸš€ Starting forecasting pipeline for {forecast_days} days...\")\n",
    "    \n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Get all active products\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT DISTINCT p.id, p.name, p.store_id, s.name as store_name\n",
    "                FROM products p\n",
    "                JOIN stores s ON p.store_id = s.id\n",
    "                WHERE p.status = 'active' AND s.status = 'active'\n",
    "                LIMIT 10\n",
    "            \"\"\")\n",
    "            \n",
    "            products = cursor.fetchall()\n",
    "        \n",
    "        total_predictions = 0\n",
    "        processed_products = 0\n",
    "        \n",
    "        for product_id, product_name, store_id, store_name in products:\n",
    "            print(f\"ðŸ”„ Processing: {product_name} ({store_name})\")\n",
    "            \n",
    "            # Generate predictions\n",
    "            predictions = generate_demand_forecast(product_id, store_id, forecast_days)\n",
    "            \n",
    "            if predictions:\n",
    "                # Insert into database\n",
    "                updated = insert_predictions(predictions, product_id, store_id)\n",
    "                total_predictions += updated\n",
    "                processed_products += 1\n",
    "                print(f\"  âœ… Generated {len(predictions)} predictions\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ Insufficient historical data\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ Forecasting pipeline complete!\")\n",
    "        print(f\"ðŸ“Š Processed: {processed_products} products\")\n",
    "        print(f\"ðŸ“ˆ Generated: {total_predictions} predictions\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pipeline error: {e}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# Run the forecasting pipeline\n",
    "success = run_forecasting_pipeline(forecast_days=30)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… Forecasting pipeline completed successfully!\")\n",
    "    print(\"ðŸ“Š Check your forecasting dashboard for updated predictions\")\n",
    "    print(\"ðŸŒ Visit: /forecasting in your InvenCare application\")\n",
    "else:\n",
    "    print(\"\\nâŒ Forecasting pipeline failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_forecasting_results():\n",
    "    \"\"\"View the generated forecasting results\"\"\"\n",
    "    connection = get_database_connection()\n",
    "    if not connection:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load latest predictions\n",
    "        query = \"\"\"\n",
    "        SELECT dp.prediction_date, dp.predicted_demand, \n",
    "               p.name as product_name, s.name as store_name\n",
    "        FROM demand_predictions dp\n",
    "        JOIN products p ON dp.product_id = p.id\n",
    "        JOIN stores s ON dp.store_id = s.id\n",
    "        WHERE dp.prediction_date >= CURDATE()\n",
    "        AND dp.prediction_date <= DATE_ADD(CURDATE(), INTERVAL 7 DAY)\n",
    "        ORDER BY dp.prediction_date, p.name\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions_df = pd.read_sql(query, connection)\n",
    "        \n",
    "        if len(predictions_df) == 0:\n",
    "            print(\"âš ï¸ No predictions found\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(predictions_df)} predictions for the next 7 days\")\n",
    "        \n",
    "        # Convert date column\n",
    "        predictions_df['prediction_date'] = pd.to_datetime(predictions_df['prediction_date'])\n",
    "        \n",
    "        # Show sample results\n",
    "        print(\"\\nðŸ“ˆ Sample Predictions:\")\n",
    "        print(\"=\" * 50)\n",
    "        for _, row in predictions_df.head(10).iterrows():\n",
    "            print(f\"{row['prediction_date'].strftime('%Y-%m-%d')}: {row['product_name']} ({row['store_name']}) - {row['predicted_demand']:.1f} units\")\n",
    "        \n",
    "        # Daily totals\n",
    "        daily_totals = predictions_df.groupby('prediction_date')['predicted_demand'].sum()\n",
    "        print(\"\\nðŸ“Š Daily Demand Totals:\")\n",
    "        print(\"=\" * 25)\n",
    "        for date, total in daily_totals.items():\n",
    "            print(f\"{date.strftime('%Y-%m-%d')}: {total:.1f} units\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nðŸ“ˆ Summary:\")\n",
    "        print(f\"Total 7-day demand: {predictions_df['predicted_demand'].sum():.0f} units\")\n",
    "        print(f\"Average daily demand: {daily_totals.mean():.1f} units\")\n",
    "        print(f\"Peak demand day: {daily_totals.idxmax().strftime('%Y-%m-%d')} ({daily_totals.max():.1f} units)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error viewing results: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if connection and connection.open:\n",
    "            connection.close()\n",
    "\n",
    "# View the results\n",
    "print(\"ðŸ“Š Viewing forecasting results...\")\n",
    "view_forecasting_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Daily Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_forecasting_update():\n",
    "    \"\"\"Main function for daily forecasting update\"\"\"\n",
    "    print(f\"\\nðŸ• Starting daily forecasting update at {datetime.now()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Test database connection\n",
    "        print(\"\\n1ï¸âƒ£ Testing database connection...\")\n",
    "        if not test_database_connection():\n",
    "            print(\"âŒ Database connection failed - aborting update\")\n",
    "            return False\n",
    "        \n",
    "        # 2. Ensure tables exist\n",
    "        print(\"\\n2ï¸âƒ£ Verifying forecasting tables...\")\n",
    "        if not create_forecasting_tables():\n",
    "            print(\"âŒ Table verification failed - aborting update\")\n",
    "            return False\n",
    "        \n",
    "        # 3. Register models\n",
    "        print(\"\\n3ï¸âƒ£ Registering forecasting models...\")\n",
    "        register_forecasting_models()\n",
    "        \n",
    "        # 4. Run forecasting pipeline\n",
    "        print(\"\\n4ï¸âƒ£ Running forecasting pipeline...\")\n",
    "        success = run_forecasting_pipeline(forecast_days=30)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\nâœ… Daily forecasting update completed successfully at {datetime.now()}\")\n",
    "            print(\"ðŸ“Š New predictions are now available in your dashboard!\")\n",
    "            print(\"ðŸŒ Visit: /forecasting to view results\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\nâŒ Daily forecasting update failed at {datetime.now()}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error in daily update: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the daily update\n",
    "print(\"ðŸ§ª Running daily forecasting update...\")\n",
    "update_result = daily_forecasting_update()\n",
    "print(f\"\\nUpdate result: {'âœ… Success' if update_result else 'âŒ Failed'}\")\n",
    "\n",
    "if update_result:\n",
    "    print(\"\\nðŸŽ¯ Next steps:\")\n",
    "    print(\"1. Check your forecasting dashboard at /forecasting\")\n",
    "    print(\"2. Review the generated predictions\")\n",
    "    print(\"3. Set up this notebook to run daily for continuous forecasting\")\n",
    "    print(\"4. Monitor prediction accuracy over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ‰ SageMaker Forecasting Pipeline Complete!\")\n",
    "print(\"\\nðŸ“‹ What was accomplished:\")\n",
    "print(\"âœ… Connected to your RDS database using pymysql\")\n",
    "print(\"âœ… Initialized SageMaker environment\")\n",
    "print(\"âœ… Created/verified forecasting database tables\")\n",
    "print(\"âœ… Registered forecasting models\")\n",
    "print(\"âœ… Generated demand predictions for 30 days\")\n",
    "print(\"âœ… Updated database with new predictions\")\n",
    "\n",
    "print(\"\\nðŸ”„ For daily automation:\")\n",
    "print(\"1. Save this notebook in your SageMaker environment\")\n",
    "print(\"2. Set up a SageMaker Pipeline or EventBridge rule\")\n",
    "print(\"3. Run the daily_forecasting_update() function daily\")\n",
    "print(\"4. Monitor results in your /forecasting dashboard\")\n",
    "\n",
    "print(\"\\nðŸŒ Check your InvenCare application at /forecasting to see the new predictions!\")\n",
    "print(f\"\\nâ° Script completed at: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
